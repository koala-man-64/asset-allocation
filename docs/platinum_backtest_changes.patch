diff --git a/asset_allocation/backtest/cli.py b/asset_allocation/backtest/cli.py
index 0b183ed..a2fa3b3 100644
--- a/asset_allocation/backtest/cli.py
+++ b/asset_allocation/backtest/cli.py
@@ -6,7 +6,6 @@ from pathlib import Path
 from typing import Optional, Sequence
 
 from asset_allocation.backtest.config import BacktestConfig
-from asset_allocation.backtest.data_access import load_backtest_inputs
 from asset_allocation.backtest.runner import run_backtest
 
 
@@ -34,13 +33,10 @@ def main(argv: Optional[Sequence[str]] = None) -> int:
 
     try:
         cfg = BacktestConfig.from_yaml(args.config, strict=bool(args.strict))
-        prices, signals = load_backtest_inputs(cfg)
 
         output_dir = Path(args.output_dir) if args.output_dir else None
         result = run_backtest(
             cfg,
-            prices=prices,
-            signals=signals,
             run_id=args.run_id,
             output_base_dir=output_dir,
         )
diff --git a/asset_allocation/backtest/config.py b/asset_allocation/backtest/config.py
index 71f2782..ae2faba 100644
--- a/asset_allocation/backtest/config.py
+++ b/asset_allocation/backtest/config.py
@@ -48,7 +48,17 @@ _STRICT_ALLOWED_SECTIONS: Dict[str, set[str]] = {
     "data": {"price_source", "price_path", "signal_path", "price_fields", "frequency"},
     "strategy": {"class", "class_name", "module", "parameters"},
     "sizing": {"class", "class_name", "module", "parameters"},
-    "constraints": {"max_leverage", "max_position_size", "allow_short", "stop_loss", "max_turnover", "max_net_exposure"},
+    "constraints": {
+        "max_leverage",
+        "max_position_size",
+        "allow_short",
+        "stop_loss",
+        "max_turnover",
+        "max_net_exposure",
+        "net_exposure_min",
+        "net_exposure_max",
+        "min_weight_change",
+    },
     "broker": {"slippage_bps", "commission", "fill_policy"},
     "output": {
         "local_dir",
@@ -183,6 +193,9 @@ class ConstraintsConfig:
     stop_loss: Optional[float] = None
     max_turnover: Optional[float] = None
     max_net_exposure: Optional[float] = None
+    net_exposure_min: Optional[float] = None
+    net_exposure_max: Optional[float] = None
+    min_weight_change: Optional[float] = None
 
     @staticmethod
     def from_dict(data: Dict[str, Any]) -> "ConstraintsConfig":
@@ -198,6 +211,15 @@ class ConstraintsConfig:
         max_net_exposure = data.get("max_net_exposure")
         if max_net_exposure is not None:
             max_net_exposure = float(max_net_exposure)
+        net_exposure_min = data.get("net_exposure_min")
+        if net_exposure_min is not None:
+            net_exposure_min = float(net_exposure_min)
+        net_exposure_max = data.get("net_exposure_max")
+        if net_exposure_max is not None:
+            net_exposure_max = float(net_exposure_max)
+        min_weight_change = data.get("min_weight_change")
+        if min_weight_change is not None:
+            min_weight_change = float(min_weight_change)
         return ConstraintsConfig(
             max_leverage=max_leverage,
             max_position_size=max_position_size,
@@ -205,6 +227,9 @@ class ConstraintsConfig:
             stop_loss=stop_loss,
             max_turnover=max_turnover,
             max_net_exposure=max_net_exposure,
+            net_exposure_min=net_exposure_min,
+            net_exposure_max=net_exposure_max,
+            min_weight_change=min_weight_change,
         )
 
     def validate(self) -> None:
@@ -218,6 +243,18 @@ class ConstraintsConfig:
             raise ValueError("constraints.max_turnover must be in (0, 10] when set.")
         if self.max_net_exposure is not None and not (0 <= float(self.max_net_exposure) <= 10.0):
             raise ValueError("constraints.max_net_exposure must be in [0, 10] when set.")
+        if self.net_exposure_min is not None and not (-10.0 <= float(self.net_exposure_min) <= 10.0):
+            raise ValueError("constraints.net_exposure_min must be in [-10, 10] when set.")
+        if self.net_exposure_max is not None and not (-10.0 <= float(self.net_exposure_max) <= 10.0):
+            raise ValueError("constraints.net_exposure_max must be in [-10, 10] when set.")
+        if (
+            self.net_exposure_min is not None
+            and self.net_exposure_max is not None
+            and float(self.net_exposure_min) > float(self.net_exposure_max)
+        ):
+            raise ValueError("constraints.net_exposure_min must be <= constraints.net_exposure_max when both are set.")
+        if self.min_weight_change is not None and not (0.0 <= float(self.min_weight_change) <= 10.0):
+            raise ValueError("constraints.min_weight_change must be in [0, 10] when set.")
 
     def to_dict(self) -> Dict[str, Any]:
         return {
@@ -227,6 +264,9 @@ class ConstraintsConfig:
             "stop_loss": self.stop_loss,
             "max_turnover": self.max_turnover,
             "max_net_exposure": self.max_net_exposure,
+            "net_exposure_min": self.net_exposure_min,
+            "net_exposure_max": self.net_exposure_max,
+            "min_weight_change": self.min_weight_change,
         }
 
 
diff --git a/asset_allocation/backtest/constraints.py b/asset_allocation/backtest/constraints.py
index 3f254a3..9795675 100644
--- a/asset_allocation/backtest/constraints.py
+++ b/asset_allocation/backtest/constraints.py
@@ -100,8 +100,49 @@ class Constraints:
             _hit("max_leverage", before=gross, after=max_lev, scale=scale)
             weights = {s: w * scale for s, w in weights.items() if abs(w * scale) >= 1e-12}
 
-        # Optional net exposure cap (absolute).
-        if self.config.max_net_exposure is not None and weights:
+        # Net exposure constraints:
+        # - If net_exposure_min/max are set, enforce a band.
+        # - Otherwise, use max_net_exposure (absolute cap) if provided.
+        net_min = self.config.net_exposure_min
+        net_max = self.config.net_exposure_max
+
+        if weights and (net_min is not None or net_max is not None):
+            net = sum(weights.values())
+            long_sum = sum(w for w in weights.values() if w > 0)
+            short_sum = sum(w for w in weights.values() if w < 0)  # negative
+
+            if net_min is not None and net < float(net_min):
+                # Increase net by reducing short exposure (safe: never increases gross).
+                if short_sum < 0:
+                    desired = float(net_min)
+                    factor = (desired - long_sum) / short_sum  # short_sum < 0
+                    factor = max(0.0, min(1.0, float(factor)))
+                    new_weights = {s: (w * factor if w < 0 else w) for s, w in weights.items()}
+                    new_net = sum(new_weights.values())
+                    _hit("net_exposure_min", before=net, after=new_net, min_net=desired, factor=factor)
+                    weights = {s: w for s, w in new_weights.items() if abs(w) >= 1e-12}
+                else:
+                    _hit("net_exposure_min_unachievable", before=net, after=net, min_net=float(net_min))
+
+            if net_max is not None and weights:
+                net = sum(weights.values())
+                long_sum = sum(w for w in weights.values() if w > 0)
+                short_sum = sum(w for w in weights.values() if w < 0)
+                if net > float(net_max):
+                    # Decrease net by reducing long exposure (safe: never increases gross).
+                    if long_sum > 0:
+                        desired = float(net_max)
+                        factor = (desired - short_sum) / long_sum
+                        factor = max(0.0, min(1.0, float(factor)))
+                        new_weights = {s: (w * factor if w > 0 else w) for s, w in weights.items()}
+                        new_net = sum(new_weights.values())
+                        _hit("net_exposure_max", before=net, after=new_net, max_net=desired, factor=factor)
+                        weights = {s: w for s, w in new_weights.items() if abs(w) >= 1e-12}
+                    else:
+                        _hit("net_exposure_max_unachievable", before=net, after=net, max_net=float(net_max))
+
+        # Optional net exposure cap (absolute), preserved for backwards compatibility.
+        if net_min is None and net_max is None and self.config.max_net_exposure is not None and weights:
             net = sum(weights.values())
             cap = float(self.config.max_net_exposure)
             if abs(net) > cap and abs(net) > 0:
@@ -110,7 +151,7 @@ class Constraints:
                 weights = {s: w * scale for s, w in weights.items() if abs(w * scale) >= 1e-12}
 
         # Optional turnover cap (approximate, using close prices and equity at close).
-        if self.config.max_turnover is not None and weights and portfolio and close_prices:
+        if (self.config.min_weight_change is not None or self.config.max_turnover is not None) and weights and portfolio and close_prices:
             equity = float(portfolio.equity)
             if equity > 0:
                 current_weights: Dict[str, float] = {}
@@ -120,27 +161,50 @@ class Constraints:
                         continue
                     current_weights[str(sym)] = (float(shares) * float(px)) / equity
 
-                all_symbols = set(current_weights.keys()) | set(weights.keys())
-                turnover = 0.0
-                deltas: Dict[str, float] = {}
-                for sym in all_symbols:
-                    cur = float(current_weights.get(sym, 0.0))
-                    tgt = float(weights.get(sym, 0.0))
-                    delta = tgt - cur
-                    deltas[sym] = delta
-                    turnover += abs(delta)
-
-                cap = float(self.config.max_turnover)
-                if turnover > cap and turnover > 0:
-                    factor = cap / turnover
-                    _hit("max_turnover", before=turnover, after=cap, factor=factor)
-                    constrained: Dict[str, float] = {}
-                    for sym, delta in deltas.items():
+                # Optional drift threshold: suppress tiny per-symbol weight changes.
+                if self.config.min_weight_change is not None and weights:
+                    threshold = float(self.config.min_weight_change)
+                    if threshold > 0:
+                        all_symbols = set(current_weights.keys()) | set(weights.keys())
+                        clipped = 0
+                        adjusted: Dict[str, float] = {}
+                        for sym in all_symbols:
+                            cur = float(current_weights.get(sym, 0.0))
+                            tgt = float(weights.get(sym, 0.0))
+                            if abs(tgt - cur) < threshold:
+                                if abs(tgt - cur) >= 1e-12:
+                                    clipped += 1
+                                new = cur
+                            else:
+                                new = tgt
+                            if abs(new) >= 1e-12:
+                                adjusted[sym] = float(new)
+                        if clipped:
+                            _hit("min_weight_change", threshold=threshold, clipped=clipped)
+                        weights = adjusted
+
+                if self.config.max_turnover is not None and weights:
+                    all_symbols = set(current_weights.keys()) | set(weights.keys())
+                    turnover = 0.0
+                    deltas: Dict[str, float] = {}
+                    for sym in all_symbols:
                         cur = float(current_weights.get(sym, 0.0))
-                        new = cur + factor * float(delta)
-                        if abs(new) >= 1e-12:
-                            constrained[sym] = float(new)
-                    weights = constrained
+                        tgt = float(weights.get(sym, 0.0))
+                        delta = tgt - cur
+                        deltas[sym] = delta
+                        turnover += abs(delta)
+
+                    cap = float(self.config.max_turnover)
+                    if turnover > cap and turnover > 0:
+                        factor = cap / turnover
+                        _hit("max_turnover", before=turnover, after=cap, factor=factor)
+                        constrained: Dict[str, float] = {}
+                        for sym, delta in deltas.items():
+                            cur = float(current_weights.get(sym, 0.0))
+                            new = cur + factor * float(delta)
+                            if abs(new) >= 1e-12:
+                                constrained[sym] = float(new)
+                        weights = constrained
 
         return ConstraintResult(weights=weights, hits=hits)
 
diff --git a/asset_allocation/backtest/engine.py b/asset_allocation/backtest/engine.py
index 6ef5467..e77ac29 100644
--- a/asset_allocation/backtest/engine.py
+++ b/asset_allocation/backtest/engine.py
@@ -154,6 +154,7 @@ class BacktestEngine:
 
             day_commission = float(costs.commission) if costs else 0.0
             day_slippage = float(costs.slippage_cost) if costs else 0.0
+            day_n_trades = int(len(fills)) if fills else 0
             day_turnover = 0.0
             if fills and prev_equity:
                 traded_value = sum(abs(f.notional) for f in fills)
@@ -171,6 +172,7 @@ class BacktestEngine:
                 turnover=day_turnover,
                 commission=day_commission,
                 slippage_cost=day_slippage,
+                n_trades=day_n_trades,
             )
             self.reporter.record_positions_snapshot(
                 current_date,
diff --git a/asset_allocation/backtest/reporter.py b/asset_allocation/backtest/reporter.py
index 5615110..2f66a6a 100644
--- a/asset_allocation/backtest/reporter.py
+++ b/asset_allocation/backtest/reporter.py
@@ -8,6 +8,7 @@ from datetime import date, datetime, timezone
 from pathlib import Path
 from typing import Any, Dict, List, Optional
 
+import numpy as np
 import pandas as pd
 from filelock import FileLock
 
@@ -48,6 +49,22 @@ def _sharpe(daily_returns: pd.Series, *, periods_per_year: int = 252) -> Optiona
     return (mean / std) * math.sqrt(periods_per_year)
 
 
+def _rolling_max_drawdown(values: "pd.Series | list[float]") -> float:
+    peak = None
+    worst = 0.0
+    for raw in values:
+        v = _safe_float(raw)
+        if v is None:
+            continue
+        if peak is None or v > peak:
+            peak = v
+        if peak and peak > 0:
+            dd = v / peak - 1.0
+            if dd < worst:
+                worst = dd
+    return float(worst)
+
+
 @dataclass
 class Reporter:
     config: BacktestConfig
@@ -95,6 +112,7 @@ class Reporter:
         turnover: float,
         commission: float,
         slippage_cost: float,
+        n_trades: int = 0,
     ) -> None:
         self._days.append(
             {
@@ -109,6 +127,7 @@ class Reporter:
                 "turnover": float(turnover),
                 "commission": float(commission),
                 "slippage_cost": float(slippage_cost),
+                "n_trades": int(n_trades),
             }
         )
 
@@ -179,6 +198,8 @@ class Reporter:
 
         if self.config.output.save_metrics_parquet:
             daily_df.to_parquet(self.output_dir / "metrics_timeseries.parquet", index=False)
+            rolling_df = self._compute_rolling_metrics(daily_df)
+            rolling_df.to_parquet(self.output_dir / "metrics_rolling.parquet", index=False)
 
         if self.config.output.save_positions_snapshot:
             positions_df = pd.DataFrame(self._positions)
@@ -249,6 +270,67 @@ class Reporter:
 
         return summary
 
+    def _compute_rolling_metrics(self, daily_df: pd.DataFrame) -> pd.DataFrame:
+        if daily_df is None or daily_df.empty:
+            return pd.DataFrame()
+
+        working = daily_df.copy()
+        working["date"] = pd.to_datetime(working["date"], errors="coerce")
+        working = working.dropna(subset=["date"]).sort_values("date").reset_index(drop=True)
+        if working.empty:
+            return pd.DataFrame()
+
+        working["daily_return"] = pd.to_numeric(working.get("daily_return"), errors="coerce").fillna(0.0)
+        working["portfolio_value"] = pd.to_numeric(working.get("portfolio_value"), errors="coerce")
+        working["turnover"] = pd.to_numeric(working.get("turnover"), errors="coerce").fillna(0.0)
+        working["commission"] = pd.to_numeric(working.get("commission"), errors="coerce").fillna(0.0)
+        working["slippage_cost"] = pd.to_numeric(working.get("slippage_cost"), errors="coerce").fillna(0.0)
+        working["n_trades"] = pd.to_numeric(working.get("n_trades"), errors="coerce").fillna(0.0)
+        working["gross_exposure"] = pd.to_numeric(working.get("gross_exposure"), errors="coerce").fillna(0.0)
+        working["net_exposure"] = pd.to_numeric(working.get("net_exposure"), errors="coerce").fillna(0.0)
+
+        # Long-form rolling metrics: one row per (date, window_days).
+        windows = [21, 63, 126, 252]
+        dr = working["daily_return"].astype(float)
+        pv = working["portfolio_value"].astype(float)
+
+        rows: List[pd.DataFrame] = []
+        for window in windows:
+            w = int(window)
+            if w <= 1:
+                continue
+
+            compounded = (1.0 + dr).rolling(w).apply(lambda x: float(np.prod(x)), raw=True) - 1.0
+            vol = dr.rolling(w).std(ddof=0) * math.sqrt(252)
+            mean = dr.rolling(w).mean() * 252
+            sharpe = mean / (vol.replace(0.0, pd.NA))
+
+            max_dd = pv.rolling(w).apply(_rolling_max_drawdown, raw=False)
+
+            out = pd.DataFrame(
+                {
+                    "date": working["date"].dt.date.astype(str),
+                    "window_days": w,
+                    "rolling_return": compounded.astype(float),
+                    "rolling_volatility": vol.astype(float),
+                    "rolling_sharpe": pd.to_numeric(sharpe, errors="coerce"),
+                    "rolling_max_drawdown": pd.to_numeric(max_dd, errors="coerce"),
+                    "turnover_sum": working["turnover"].rolling(w).sum().astype(float),
+                    "commission_sum": working["commission"].rolling(w).sum().astype(float),
+                    "slippage_cost_sum": working["slippage_cost"].rolling(w).sum().astype(float),
+                    "n_trades_sum": working["n_trades"].rolling(w).sum().astype(float),
+                    "gross_exposure_avg": working["gross_exposure"].rolling(w).mean().astype(float),
+                    "net_exposure_avg": working["net_exposure"].rolling(w).mean().astype(float),
+                }
+            )
+            rows.append(out)
+
+        if not rows:
+            return pd.DataFrame()
+
+        combined = pd.concat(rows, ignore_index=True)
+        return combined.sort_values(["date", "window_days"]).reset_index(drop=True)
+
     def _write_periodic_returns(self, daily_df: pd.DataFrame) -> None:
         if "date" not in daily_df.columns or "portfolio_value" not in daily_df.columns:
             return
diff --git a/asset_allocation/backtest/runner.py b/asset_allocation/backtest/runner.py
index 8e98d2b..f47c33b 100644
--- a/asset_allocation/backtest/runner.py
+++ b/asset_allocation/backtest/runner.py
@@ -15,6 +15,7 @@ from asset_allocation.backtest.strategy import (
     BreakoutStrategy,
     BuyAndHoldStrategy,
     EpisodicPivotStrategy,
+    LongShortTopNStrategy,
     StaticUniverseStrategy,
     Strategy,
     TopNSignalStrategy,
@@ -63,6 +64,27 @@ def _build_strategy(config: BacktestConfig) -> Strategy:
             partial_exit_fraction=float(params.get("partial_exit_fraction", 0.5)),
             rebalance=params.get("rebalance", "daily"),
         )
+    if name == "LongShortTopNStrategy":
+        return LongShortTopNStrategy(
+            signal_column=str(params.get("signal_column") or "composite_percentile"),
+            k_long=int(params.get("k_long", 0)),
+            k_short=int(params.get("k_short", 0)),
+            long_if_high=bool(params.get("long_if_high", True)),
+            min_abs_score=float(params.get("min_abs_score", 0.0)),
+            trailing_ma_days=int(params["trailing_ma_days"])
+            if "trailing_ma_days" in params and params["trailing_ma_days"] is not None
+            else None,
+            stop_loss_pct=float(params["stop_loss_pct"])
+            if "stop_loss_pct" in params and params["stop_loss_pct"] is not None
+            else None,
+            use_low_for_stop=bool(params.get("use_low_for_stop", True)),
+            partial_exit_days=int(params["partial_exit_days"])
+            if "partial_exit_days" in params and params["partial_exit_days"] is not None
+            else None,
+            partial_exit_fraction=float(params.get("partial_exit_fraction", 0.5)),
+            max_hold_days=int(params["max_hold_days"]) if "max_hold_days" in params and params["max_hold_days"] is not None else None,
+            rebalance=params.get("rebalance", "daily"),
+        )
     if name == "EpisodicPivotStrategy":
         return EpisodicPivotStrategy(
             ep_score_column=str(params.get("ep_score_column") or "ep_score"),
@@ -120,11 +142,19 @@ def _build_sizer(config: BacktestConfig) -> Sizer:
 def run_backtest(
     config: BacktestConfig,
     *,
-    prices: pd.DataFrame,
+    prices: Optional[pd.DataFrame] = None,
     signals: Optional[pd.DataFrame] = None,
     run_id: Optional[str] = None,
     output_base_dir: Optional[Path] = None,
 ) -> BacktestRunResult:
+    if prices is None:
+        from asset_allocation.backtest.data_access import load_backtest_inputs
+
+        loaded_prices, loaded_signals = load_backtest_inputs(config)
+        prices = loaded_prices
+        if signals is None:
+            signals = loaded_signals
+
     resolved_run_id = run_id or generate_run_id()
     reporter = Reporter.create(config, run_id=resolved_run_id, output_dir=output_base_dir)
 
diff --git a/asset_allocation/backtest/service/job_manager.py b/asset_allocation/backtest/service/job_manager.py
index 2f5b04c..680e15c 100644
--- a/asset_allocation/backtest/service/job_manager.py
+++ b/asset_allocation/backtest/service/job_manager.py
@@ -8,7 +8,6 @@ from pathlib import Path
 from typing import Dict
 
 from asset_allocation.backtest.config import BacktestConfig
-from asset_allocation.backtest.data_access import load_backtest_inputs
 from asset_allocation.backtest.runner import run_backtest
 from asset_allocation.backtest.service.adls_uploader import upload_run_artifacts
 from asset_allocation.backtest.service.run_store import RunStore
@@ -46,11 +45,8 @@ class JobManager:
                 # Ensure artifacts reflect the effective output base dir in config.yaml.
                 effective = replace(config, output=replace(config.output, local_dir=str(self._output_base_dir)))
 
-                prices, signals = load_backtest_inputs(effective)
                 result = run_backtest(
                     effective,
-                    prices=prices,
-                    signals=signals,
                     run_id=run_id,
                     output_base_dir=self._output_base_dir,
                 )
diff --git a/asset_allocation/backtest/strategy.py b/asset_allocation/backtest/strategy.py
index 230ed02..51f533b 100644
--- a/asset_allocation/backtest/strategy.py
+++ b/asset_allocation/backtest/strategy.py
@@ -319,6 +319,270 @@ class TopNSignalStrategy(Strategy):
         return StrategyDecision(scores={row["symbol"]: float(row["signal"]) for _, row in df.iterrows()})
 
 
+class LongShortTopNStrategy(Strategy):
+    """
+    Generic Platinum-driven long/short strategy using a single score column.
+
+    - Signals are used as-is (no recomputation).
+    - Targets are generated at close(T) and executed at open(T+1) by the engine.
+    - Produces signed scores:
+        - long candidates => positive scores
+        - short candidates => negative scores
+
+    Selection rules (per rebalance date):
+      - If long_if_high=True: longs from highest scores, shorts from lowest scores.
+      - If long_if_high=False: longs from lowest scores, shorts from highest scores.
+
+    Exits are evaluated on daily bars using prices (close/T+0):
+      - optional trailing moving average
+      - optional stop loss
+      - optional max holding period (trading days)
+
+    Partial exits (v1) are expressed as per-symbol scaling via StrategyDecision.scales.
+    """
+
+    def __init__(
+        self,
+        *,
+        signal_column: str,
+        k_long: int = 0,
+        k_short: int = 0,
+        long_if_high: bool = True,
+        min_abs_score: float = 0.0,
+        trailing_ma_days: Optional[int] = None,
+        stop_loss_pct: Optional[float] = None,
+        use_low_for_stop: bool = True,
+        partial_exit_days: Optional[int] = None,
+        partial_exit_fraction: float = 0.5,
+        max_hold_days: Optional[int] = None,
+        rebalance: str | int = "daily",
+    ):
+        super().__init__(rebalance=rebalance)
+        self._signal_column = str(signal_column)
+        self._k_long = int(k_long)
+        self._k_short = int(k_short)
+        self._long_if_high = bool(long_if_high)
+        self._min_abs_score = float(min_abs_score)
+        self._trailing_ma_days = int(trailing_ma_days) if trailing_ma_days is not None else None
+        self._stop_loss_pct = float(stop_loss_pct) if stop_loss_pct is not None else None
+        self._use_low_for_stop = bool(use_low_for_stop)
+        self._partial_exit_days = int(partial_exit_days) if partial_exit_days is not None else None
+        self._partial_exit_fraction = float(partial_exit_fraction)
+        self._max_hold_days = int(max_hold_days) if max_hold_days is not None else None
+
+        self._entry_date: Dict[str, date] = {}
+        self._entry_price: Dict[str, float] = {}
+        self._entry_side: Dict[str, int] = {}
+        self._scales: Dict[str, float] = {}
+        self._last_score: Dict[str, float] = {}
+
+    def _sync_positions(self, as_of: date, *, prices: pd.DataFrame, portfolio: PortfolioSnapshot) -> None:
+        held = {s: float(sh) for s, sh in (portfolio.positions or {}).items() if abs(float(sh)) >= 1e-12}
+
+        for sym in list(self._entry_date.keys()):
+            if sym not in held:
+                self._entry_date.pop(sym, None)
+                self._entry_price.pop(sym, None)
+                self._entry_side.pop(sym, None)
+                self._scales.pop(sym, None)
+                self._last_score.pop(sym, None)
+
+        for sym, shares in held.items():
+            side = 1 if shares > 0 else -1
+            if self._entry_side.get(sym) != side:
+                open_px = _latest_bar_value(prices, as_of=as_of, symbol=sym, columns=["open", "Open"])
+                close_px = _latest_bar_value(prices, as_of=as_of, symbol=sym, columns=["close", "Close"])
+                entry_px = open_px if open_px is not None else close_px
+                if entry_px is not None:
+                    self._entry_date[sym] = as_of
+                    self._entry_price[sym] = float(entry_px)
+                    self._entry_side[sym] = side
+                    self._scales[sym] = 1.0
+
+    def _should_exit(self, *, as_of: date, symbol: str, side: int, prices: pd.DataFrame) -> bool:
+        close_px = _latest_bar_value(prices, as_of=as_of, symbol=symbol, columns=["close", "Close"])
+        if close_px is None:
+            return False
+
+        if self._trailing_ma_days is not None and self._trailing_ma_days > 0:
+            ma = _moving_average_close(prices, symbol=symbol, window=self._trailing_ma_days)
+            if ma is not None:
+                if side > 0 and close_px < ma:
+                    return True
+                if side < 0 and close_px > ma:
+                    return True
+
+        if self._max_hold_days is not None and self._max_hold_days > 0:
+            entry_date = self._entry_date.get(symbol)
+            if entry_date is not None:
+                held_days = _trading_days_held(prices, symbol=symbol, entry_date=entry_date, as_of=as_of)
+                if held_days >= self._max_hold_days:
+                    return True
+
+        if self._stop_loss_pct is None:
+            return False
+
+        entry_px = self._entry_price.get(symbol)
+        if entry_px is None:
+            return False
+
+        if side > 0:
+            trigger_px = close_px
+            if self._use_low_for_stop:
+                low_px = _latest_bar_value(prices, as_of=as_of, symbol=symbol, columns=["low", "Low"])
+                if low_px is not None:
+                    trigger_px = low_px
+            return trigger_px <= float(entry_px) * (1.0 - float(self._stop_loss_pct))
+
+        trigger_px = close_px
+        high_px = _latest_bar_value(prices, as_of=as_of, symbol=symbol, columns=["high", "High"])
+        if high_px is not None:
+            trigger_px = high_px
+        return trigger_px >= float(entry_px) * (1.0 + float(self._stop_loss_pct))
+
+    @staticmethod
+    def _coerce_signal_map(signals: Optional[pd.DataFrame], *, signal_column: str) -> Dict[str, float]:
+        if signals is None or signals.empty:
+            return {}
+        if "symbol" not in signals.columns:
+            raise ValueError("signals must include 'symbol'.")
+        if signal_column not in signals.columns:
+            raise ValueError(f"signals missing required column: {signal_column!r}")
+
+        df = signals[["symbol", signal_column]].copy()
+        df["symbol"] = df["symbol"].astype(str)
+        df["signal"] = pd.to_numeric(df[signal_column], errors="coerce")
+        df = df.dropna(subset=["signal"]).drop_duplicates(subset=["symbol"], keep="last")
+        if df.empty:
+            return {}
+        return {str(row["symbol"]): float(row["signal"]) for _, row in df.iterrows()}
+
+    @staticmethod
+    def _select_topn(
+        signals: pd.DataFrame,
+        *,
+        k_long: int,
+        k_short: int,
+        long_if_high: bool,
+        min_abs_score: float,
+    ) -> Dict[str, float]:
+        if signals is None or signals.empty:
+            return {}
+
+        df = signals.copy()
+        df["symbol"] = df["symbol"].astype(str)
+        df["signal"] = pd.to_numeric(df["signal"], errors="coerce")
+        df = df.dropna(subset=["signal"]).drop_duplicates(subset=["symbol"], keep="last")
+        if df.empty:
+            return {}
+
+        if min_abs_score > 0:
+            df = df[df["signal"].abs() >= float(min_abs_score)]
+            if df.empty:
+                return {}
+
+        # Select longs first, then shorts from remaining universe to prevent overlap.
+        out: Dict[str, float] = {}
+
+        if k_long > 0:
+            long_sorted = df.sort_values("signal", ascending=not long_if_high)
+            long_df = long_sorted.head(int(k_long))
+            for _, row in long_df.iterrows():
+                sym = str(row["symbol"])
+                value = _safe_float(row["signal"])
+                if value is None:
+                    continue
+                out[sym] = abs(float(value))
+            df = df[~df["symbol"].isin(set(long_df["symbol"].tolist()))]
+
+        if k_short > 0 and not df.empty:
+            short_sorted = df.sort_values("signal", ascending=long_if_high)
+            short_df = short_sorted.head(int(k_short))
+            for _, row in short_df.iterrows():
+                sym = str(row["symbol"])
+                value = _safe_float(row["signal"])
+                if value is None:
+                    continue
+                out[sym] = -abs(float(value))
+
+        return out
+
+    def on_bar(
+        self,
+        as_of: date,
+        *,
+        prices: pd.DataFrame,
+        signals: Optional[pd.DataFrame],
+        portfolio: PortfolioSnapshot,
+    ) -> Optional[StrategyDecision]:
+        self._sync_positions(as_of, prices=prices, portfolio=portfolio)
+
+        held = {s: float(sh) for s, sh in (portfolio.positions or {}).items() if abs(float(sh)) >= 1e-12}
+        kept: Dict[str, float] = {}
+        scales: Dict[str, float] = {}
+        changed_non_rebalance = False
+
+        signal_map = self._coerce_signal_map(signals, signal_column=self._signal_column)
+
+        for sym, shares in held.items():
+            side = 1 if shares > 0 else -1
+            if self._should_exit(as_of=as_of, symbol=sym, side=side, prices=prices):
+                changed_non_rebalance = True
+                continue
+
+            # Refresh held score from today's signal if available (keeps ranking current at rebalance).
+            sig = signal_map.get(sym)
+            if sig is not None:
+                score = abs(float(sig)) * (1.0 if side > 0 else -1.0)
+            else:
+                score = self._last_score.get(sym)
+                if score is None:
+                    score = float(side)
+                else:
+                    score = float(score)
+                    if side > 0 and score <= 0:
+                        score = abs(score) or 1.0
+                    if side < 0 and score >= 0:
+                        score = -(abs(score) or 1.0)
+            kept[sym] = float(score)
+
+            scale = float(self._scales.get(sym, 1.0))
+            if self._partial_exit_days is not None and scale >= 0.999:
+                entry_date = self._entry_date.get(sym)
+                if entry_date is not None:
+                    held_days = _trading_days_held(prices, symbol=sym, entry_date=entry_date, as_of=as_of)
+                    if held_days >= int(self._partial_exit_days):
+                        remaining = max(0.0, 1.0 - float(self._partial_exit_fraction))
+                        if abs(remaining - scale) > 1e-12:
+                            scale = remaining
+                            self._scales[sym] = scale
+                            changed_non_rebalance = True
+            if abs(scale - 1.0) > 1e-12:
+                scales[sym] = scale
+
+        is_rebalance = self.check_rebalance(as_of)
+        if not is_rebalance and not changed_non_rebalance:
+            return None
+
+        candidates: Dict[str, float] = {}
+        if is_rebalance and signal_map:
+            df = pd.DataFrame({"symbol": list(signal_map.keys()), "signal": list(signal_map.values())})
+            candidates = self._select_topn(
+                df,
+                k_long=max(0, self._k_long),
+                k_short=max(0, self._k_short),
+                long_if_high=self._long_if_high,
+                min_abs_score=self._min_abs_score,
+            )
+
+        merged = dict(kept)
+        merged.update(candidates)
+        for sym, score in merged.items():
+            self._last_score[sym] = float(score)
+
+        return StrategyDecision(scores=merged, scales=scales)
+
+
 class StaticUniverseStrategy(Strategy):
     """
     Allocates equal signals relative to all symbols in the provided list.
diff --git a/audit_snapshot.json b/audit_snapshot.json
index 2bb894d..51a373f 100644
--- a/audit_snapshot.json
+++ b/audit_snapshot.json
@@ -1,9 +1,9 @@
 {
-  "generated_at_utc": "2026-01-18T16:51:35.395333+00:00",
+  "generated_at_utc": "2026-01-18T17:45:14.292198+00:00",
   "git": {
     "branch": "main",
-    "commit": "7a7e2e45403d7130fa09649fb0409af869364e44",
-    "status_porcelain": "M asset_allocation/backtest/config.py\n M asset_allocation/backtest/constraints.py\n M asset_allocation/backtest/engine.py\n M asset_allocation/backtest/reporter.py\n M asset_allocation/backtest/runner.py\n M asset_allocation/backtest/sizer.py\n M asset_allocation/backtest/strategy.py\n M tests/backtest/test_phase1_engine.py\n M tests/backtest/test_phase3_service_api.py\n?? docs/backtesting_architecture.jpg\n?? tests/backtest/test_breakout_and_ep_strategies.py\n?? tests/backtest/test_long_short_sizer.py"
+    "commit": "2d068c51b1d2b12b10bfd57117759e3ab02ec4d4",
+    "status_porcelain": "M asset_allocation/backtest/cli.py\n M asset_allocation/backtest/config.py\n M asset_allocation/backtest/constraints.py\n M asset_allocation/backtest/engine.py\n M asset_allocation/backtest/reporter.py\n M asset_allocation/backtest/runner.py\n M asset_allocation/backtest/service/job_manager.py\n M asset_allocation/backtest/strategy.py\n M tests/backtest/test_breakout_and_ep_strategies.py\n M tests/backtest/test_phase1_engine.py\n?? backtests/platinum_ep_continuation_long.yaml\n?? backtests/platinum_gap_and_crap_short.yaml\n?? backtests/platinum_pullback_failure_short.yaml\n?? backtests/platinum_pullback_long.yaml\n?? backtests/platinum_vcp_breakdown_short.yaml\n?? backtests/platinum_vcp_breakout_long.yaml\n?? docs/PM_gaps_analysis.md\n?? docs/backtest_framework_analysis.md\n?? docs/framework_vs_trading_desk.md\n?? tests/backtest/test_platinum_topn_strategy.py"
   },
   "github": {
     ".github/workflows": true,
diff --git a/tests/backtest/test_breakout_and_ep_strategies.py b/tests/backtest/test_breakout_and_ep_strategies.py
index 7c0b3da..3c34962 100644
--- a/tests/backtest/test_breakout_and_ep_strategies.py
+++ b/tests/backtest/test_breakout_and_ep_strategies.py
@@ -87,6 +87,7 @@ def test_breakout_strategy_long_short_smoke(tmp_path: Path) -> None:
     assert (run_dir / "trades.csv").exists()
     assert (run_dir / "daily_positions.parquet").exists()
     assert (run_dir / "metrics_timeseries.parquet").exists()
+    assert (run_dir / "metrics_rolling.parquet").exists()
     assert (run_dir / "summary.json").exists()
 
     trades = pd.read_csv(run_dir / "trades.csv")
@@ -123,6 +124,7 @@ def test_ep_strategy_long_short_smoke(tmp_path: Path) -> None:
     assert (run_dir / "trades.csv").exists()
     assert (run_dir / "daily_positions.parquet").exists()
     assert (run_dir / "metrics_timeseries.parquet").exists()
+    assert (run_dir / "metrics_rolling.parquet").exists()
     assert (run_dir / "summary.json").exists()
 
     trades = pd.read_csv(run_dir / "trades.csv")
@@ -134,4 +136,3 @@ def test_ep_strategy_long_short_smoke(tmp_path: Path) -> None:
     assert positions["date"].nunique() == 5
     assert positions["symbol"].nunique() == 2
     assert len(positions) == 10  # full snapshot: days * universe
-
diff --git a/tests/backtest/test_phase1_engine.py b/tests/backtest/test_phase1_engine.py
index 4630cfa..2acc6ea 100644
--- a/tests/backtest/test_phase1_engine.py
+++ b/tests/backtest/test_phase1_engine.py
@@ -58,6 +58,7 @@ def test_phase1_buy_and_hold_artifacts_and_execution_timing(tmp_path: Path) -> N
     assert (run_dir / "trades.csv").exists()
     assert (run_dir / "daily_metrics.csv").exists()
     assert (run_dir / "metrics_timeseries.parquet").exists()
+    assert (run_dir / "metrics_rolling.parquet").exists()
     assert (run_dir / "daily_positions.parquet").exists()
     assert (run_dir / "monthly_returns.csv").exists()
     assert (run_dir / "returns_monthly.csv").exists()
@@ -80,6 +81,9 @@ def test_phase1_buy_and_hold_artifacts_and_execution_timing(tmp_path: Path) -> N
     assert metrics.loc[0, "portfolio_value"] == pytest.approx(1000.0)
     assert metrics.loc[2, "portfolio_value"] == pytest.approx(1171.171171, rel=1e-6)
 
+    metrics_ts = pd.read_parquet(run_dir / "metrics_timeseries.parquet")
+    assert "n_trades" in metrics_ts.columns
+
     positions = pd.read_parquet(run_dir / "daily_positions.parquet")
     assert positions["date"].nunique() == 3
     assert positions["symbol"].nunique() == 1
diff --git a/backtests/platinum_ep_continuation_long.yaml b/backtests/platinum_ep_continuation_long.yaml
new file mode 100755
index 0000000..a802da7
--- /dev/null
+++ b/backtests/platinum_ep_continuation_long.yaml
@@ -0,0 +1,50 @@
+run_name: "PLATINUM-EP-CONTINUATION-LONG"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "ep_continuation_score"
+    k_long: 10
+    k_short: 0
+    long_if_high: true
+    rebalance: "daily"
+    trailing_ma_days: 20
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 10
+    max_shorts: 0
+    gross_target: 1.0
+    net_target: 1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: false
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.50
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/backtests/platinum_pullback_long.yaml b/backtests/platinum_pullback_long.yaml
new file mode 100755
index 0000000..84ca574
--- /dev/null
+++ b/backtests/platinum_pullback_long.yaml
@@ -0,0 +1,50 @@
+run_name: "PLATINUM-PULLBACK-LONG"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "pullback_score"
+    k_long: 10
+    k_short: 0
+    long_if_high: true
+    rebalance: "weekly"
+    trailing_ma_days: 20
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 10
+    max_shorts: 0
+    gross_target: 1.0
+    net_target: 1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: false
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.50
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/backtests/platinum_vcp_breakout_long.yaml b/backtests/platinum_vcp_breakout_long.yaml
new file mode 100755
index 0000000..832ed4a
--- /dev/null
+++ b/backtests/platinum_vcp_breakout_long.yaml
@@ -0,0 +1,50 @@
+run_name: "PLATINUM-VCP-BREAKOUT-LONG"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "vcp_score"
+    k_long: 10
+    k_short: 0
+    long_if_high: true
+    rebalance: "daily"
+    trailing_ma_days: 10
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 10
+    max_shorts: 0
+    gross_target: 1.0
+    net_target: 1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: false
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.50
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/backtests/platinum_vcp_breakdown_short.yaml b/backtests/platinum_vcp_breakdown_short.yaml
new file mode 100755
index 0000000..fd06550
--- /dev/null
+++ b/backtests/platinum_vcp_breakdown_short.yaml
@@ -0,0 +1,52 @@
+run_name: "PLATINUM-VCP-BREAKDOWN-SHORT"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "vcp_short_score"
+    k_long: 0
+    k_short: 10
+    long_if_high: false
+    rebalance: "daily"
+    trailing_ma_days: 10
+    partial_exit_days: 4
+    partial_exit_fraction: 0.5
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 0
+    max_shorts: 10
+    gross_target: 1.0
+    net_target: -1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: true
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.75
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/backtests/platinum_pullback_failure_short.yaml b/backtests/platinum_pullback_failure_short.yaml
new file mode 100755
index 0000000..ed4c677
--- /dev/null
+++ b/backtests/platinum_pullback_failure_short.yaml
@@ -0,0 +1,50 @@
+run_name: "PLATINUM-PULLBACK-FAILURE-SHORT"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "pullback_short_score"
+    k_long: 0
+    k_short: 10
+    long_if_high: false
+    rebalance: "weekly"
+    trailing_ma_days: 20
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 0
+    max_shorts: 10
+    gross_target: 1.0
+    net_target: -1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: true
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.75
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/backtests/platinum_gap_and_crap_short.yaml b/backtests/platinum_gap_and_crap_short.yaml
new file mode 100755
index 0000000..bec5b34
--- /dev/null
+++ b/backtests/platinum_gap_and_crap_short.yaml
@@ -0,0 +1,53 @@
+run_name: "PLATINUM-GAP-AND-CRAP-SHORT"
+start_date: "2024-01-01"
+end_date: "2024-12-31"
+initial_cash: 100000.0
+
+universe:
+  symbols:
+    - "AAPL"
+    - "MSFT"
+
+data:
+  price_source: "ADLS"
+  price_path: "silver/market-data/{symbol}"
+  signal_path: "platinum/signals/daily"
+  frequency: "Daily"
+
+strategy:
+  class: "LongShortTopNStrategy"
+  parameters:
+    signal_column: "gap_crap_score"
+    k_long: 0
+    k_short: 10
+    long_if_high: false
+    rebalance: "daily"
+    trailing_ma_days: 10
+    partial_exit_days: 3
+    partial_exit_fraction: 0.5
+    max_hold_days: 7
+
+sizing:
+  class: "LongShortScoreSizer"
+  parameters:
+    max_longs: 0
+    max_shorts: 10
+    gross_target: 1.0
+    net_target: -1.0
+    weight_mode: "equal"
+    sticky_holdings: true
+
+constraints:
+  allow_short: true
+  max_leverage: 1.0
+  max_position_size: 0.10
+  max_turnover: 0.75
+  min_weight_change: 0.002
+
+broker:
+  commission: 0.0005
+  slippage_bps: 2.0
+  fill_policy: "next_open"
+
+output:
+  local_dir: "./backtest_results"
diff --git a/tests/backtest/test_platinum_topn_strategy.py b/tests/backtest/test_platinum_topn_strategy.py
new file mode 100755
index 0000000..343de12
--- /dev/null
+++ b/tests/backtest/test_platinum_topn_strategy.py
@@ -0,0 +1,107 @@
+from __future__ import annotations
+
+from datetime import date, timedelta
+from pathlib import Path
+
+import pandas as pd
+
+from asset_allocation.backtest.config import BacktestConfig
+from asset_allocation.backtest.runner import run_backtest
+
+
+def _dates() -> list[date]:
+    start = date(2020, 1, 1)
+    return [start + timedelta(days=i) for i in range(5)]
+
+
+def _prices_frame() -> pd.DataFrame:
+    rows: list[dict[str, object]] = []
+    for i, d in enumerate(_dates()):
+        rows.append({"date": d, "symbol": "AAA", "open": 100.0 + i, "close": 101.0 + i})
+        rows.append({"date": d, "symbol": "BBB", "open": 200.0 + i, "close": 199.0 + i})
+    return pd.DataFrame(rows)
+
+
+def _signals_for_column(column: str) -> pd.DataFrame:
+    rows: list[dict[str, object]] = []
+    for d in _dates():
+        rows.append({"date": d, "symbol": "AAA", column: 2.0})
+        rows.append({"date": d, "symbol": "BBB", column: 1.0})
+    return pd.DataFrame(rows)
+
+
+def _base_config(tmp_path: Path) -> dict[str, object]:
+    return {
+        "run_name": "platinum_topn_smoke",
+        "start_date": "2020-01-01",
+        "end_date": "2020-01-05",
+        "initial_cash": 1000.0,
+        "universe": {"symbols": ["AAA", "BBB"]},
+        "broker": {"slippage_bps": 0.0, "commission": 0.0, "fill_policy": "next_open"},
+        "output": {"local_dir": str(tmp_path)},
+    }
+
+
+def test_longshort_topn_strategy_long_only_smoke(tmp_path: Path) -> None:
+    config = _base_config(tmp_path)
+    config["strategy"] = {"class": "LongShortTopNStrategy", "parameters": {"signal_column": "vcp_score", "k_long": 1}}
+    config["sizing"] = {
+        "class": "LongShortScoreSizer",
+        "parameters": {"max_longs": 1, "max_shorts": 0, "gross_target": 1.0, "net_target": 1.0, "weight_mode": "equal"},
+    }
+    config["constraints"] = {"max_leverage": 1.0, "max_position_size": 1.0, "allow_short": False}
+
+    cfg = BacktestConfig.from_dict(config)
+    result = run_backtest(
+        cfg,
+        prices=_prices_frame(),
+        signals=_signals_for_column("vcp_score"),
+        run_id="RUNTEST-PLAT-LONG",
+        output_base_dir=tmp_path,
+    )
+
+    run_dir = result.output_dir
+    assert (run_dir / "trades.csv").exists()
+    assert (run_dir / "daily_positions.parquet").exists()
+    assert (run_dir / "metrics_timeseries.parquet").exists()
+    assert (run_dir / "metrics_rolling.parquet").exists()
+    assert (run_dir / "summary.json").exists()
+
+    trades = pd.read_csv(run_dir / "trades.csv")
+    assert len(trades) >= 1
+    assert (trades["quantity"] > 0).any()
+    assert not (trades["quantity"] < 0).any()
+
+
+def test_longshort_topn_strategy_short_only_smoke(tmp_path: Path) -> None:
+    config = _base_config(tmp_path)
+    config["strategy"] = {
+        "class": "LongShortTopNStrategy",
+        "parameters": {"signal_column": "vcp_short_score", "k_short": 1, "long_if_high": False},
+    }
+    config["sizing"] = {
+        "class": "LongShortScoreSizer",
+        "parameters": {"max_longs": 0, "max_shorts": 1, "gross_target": 1.0, "net_target": -1.0, "weight_mode": "equal"},
+    }
+    config["constraints"] = {"max_leverage": 1.0, "max_position_size": 1.0, "allow_short": True}
+
+    cfg = BacktestConfig.from_dict(config)
+    result = run_backtest(
+        cfg,
+        prices=_prices_frame(),
+        signals=_signals_for_column("vcp_short_score"),
+        run_id="RUNTEST-PLAT-SHORT",
+        output_base_dir=tmp_path,
+    )
+
+    run_dir = result.output_dir
+    assert (run_dir / "trades.csv").exists()
+    assert (run_dir / "daily_positions.parquet").exists()
+    assert (run_dir / "metrics_timeseries.parquet").exists()
+    assert (run_dir / "metrics_rolling.parquet").exists()
+    assert (run_dir / "summary.json").exists()
+
+    trades = pd.read_csv(run_dir / "trades.csv")
+    assert len(trades) >= 1
+    assert (trades["quantity"] < 0).any()
+
